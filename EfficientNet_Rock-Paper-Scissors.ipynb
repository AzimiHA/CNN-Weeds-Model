{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Roboflow-EfficientNet-Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qYbI0TGpL6Jd"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYbI0TGpL6Jd"
      },
      "source": [
        "## Import EfficientNet Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4wFQJkBiFWE"
      },
      "source": [
        "# Downgrade pillow to avoid `UserWarning: Possibly corrupt EXIF data.`\n",
        "#!pip install pillow==4.0.0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "482XTFalCfB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9ac66a-3336-49ca-e0f5-c38beab09dd9"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "#in case your keras version has bumped ahead you may want to try reverting to 2.3.1\n",
        "#!pip install q keras==2.3.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MlLZ1siDhV9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f5ca73c3-58f0-4185-eab0-9c00f3e33181"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmzQmZdKDfSF"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9S4UyubKPUc"
      },
      "source": [
        "## Clone **EfficinetNet** repo\n",
        "\n",
        "Credit to [DLogogy](https://www.dlology.com/blog/transfer-learning-with-efficientnet/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnyJvYF_yXLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b650c4-198e-4ac5-c70e-b1eba2a334d6"
      },
      "source": [
        "\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        "  !git clone https://github.com/Tony607/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 171, done.\u001b[K\n",
            "remote: Total 171 (delta 0), reused 0 (delta 0), pack-reused 171\u001b[K\n",
            "Receiving objects: 100% (171/171), 5.44 MiB | 31.68 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO7kxxRaMC2q"
      },
      "source": [
        "\n",
        "\n",
        "## Import efficientnet and Choose EfficientNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq00KoYUzOSc"
      },
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "\n",
        "#Choose\n",
        "#EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "#from efficientnet import EfficientNetB2 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeETTKsszRj0"
      },
      "source": [
        "# loading pretrained conv base model\n",
        "\n",
        "#define input height and width\n",
        "width = 150\n",
        "height = 150\n",
        "#width = 300\n",
        "#height = 300\n",
        "input_shape = (height, width, 3)\n",
        "\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hogQDF7KYsmC"
      },
      "source": [
        "!curl -L \"https://public.roboflow.com/ds/gYhsu6dBil?key=XHbtDJPEbV\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
        "#Raw data sizes: 300x300\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_GD-iEkPVin"
      },
      "source": [
        "train_dir = '/content/efficientnet_keras_transfer_learning/train/'\n",
        "valid_dir = '/content/efficientnet_keras_transfer_learning/valid/'\n",
        "test_dir = '/content/efficientnet_keras_transfer_learning/test/'\n",
        "batch_size = 4\n",
        "\n",
        "\n",
        "import os\n",
        "import random\n",
        "def delete_all_but(split_path, number):\n",
        "  images = []\n",
        "  for path, subdirs, files in os.walk(split_path):\n",
        "      for name in files:\n",
        "          images.append(os.path.join(path, name))\n",
        "  if len(images) > number:\n",
        "    keep = random.sample(images, number)\n",
        "    for img in images:\n",
        "      if img not in keep:\n",
        "        os.remove(img)\n",
        "  return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9MM2WA49zyj"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to target height and width.\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        valid_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMq6-unWWWnu"
      },
      "source": [
        "# Set up EfficientNet Training Job"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp4TOw5rJs0M"
      },
      "source": [
        "import os, os.path\n",
        "epochs = 500\n",
        "NUM_TRAIN = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
        "NUM_TEST = sum([len(files) for r, d, files in os.walk(valid_dir)])\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgjoz26l-HfD"
      },
      "source": [
        "num_classes = len(os.listdir(train_dir))\n",
        "print('building netowrk for ' + str(num_classes) + ' classes')\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(3, activation='softmax', name=\"fc_out\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iAX7AegDHUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b6540a-ceb8-4747-dd28-c195d72fd0f7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnet-b0 (Model)      (None, 5, 5, 1280)        4049564   \n",
            "_________________________________________________________________\n",
            "gap (GlobalMaxPooling2D)     (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout_out (Dropout)        (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "fc_out (Dense)               (None, 3)                 3843      \n",
            "=================================================================\n",
            "Total params: 4,053,407\n",
            "Trainable params: 4,011,391\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N-F9Z-uDJAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba029a6-3ae0-4a0c-df58-200692867388"
      },
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly4ikbcSWeqV"
      },
      "source": [
        "# Run EfficientNet Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJHDUrjw2wRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a79686-aacf-4182-aa73-be0c63eb510d"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "627/630 [============================>.] - ETA: 0s - loss: 2.5762 - acc: 0.3824Epoch 1/500\n",
            "630/630 [==============================] - 25s 39ms/step - loss: 2.5677 - acc: 0.3833 - val_loss: 2.4482 - val_acc: 0.3145\n",
            "Epoch 2/500\n",
            "627/630 [============================>.] - ETA: 0s - loss: 1.9594 - acc: 0.4681Epoch 1/500\n",
            "630/630 [==============================] - 15s 25ms/step - loss: 1.9617 - acc: 0.4679 - val_loss: 2.5074 - val_acc: 0.3387\n",
            "Epoch 3/500\n",
            "627/630 [============================>.] - ETA: 0s - loss: 1.7403 - acc: 0.5156Epoch 1/500\n",
            "630/630 [==============================] - 15s 24ms/step - loss: 1.7400 - acc: 0.5155 - val_loss: 2.0469 - val_acc: 0.3468\n",
            "Epoch 4/500\n",
            "628/630 [============================>.] - ETA: 0s - loss: 1.5880 - acc: 0.5541Epoch 1/500\n",
            "630/630 [==============================] - 15s 24ms/step - loss: 1.5878 - acc: 0.5548 - val_loss: 2.2597 - val_acc: 0.3710\n",
            "Epoch 5/500\n",
            "627/630 [============================>.] - ETA: 0s - loss: 1.4055 - acc: 0.5949Epoch 1/500\n",
            "630/630 [==============================] - 16s 25ms/step - loss: 1.4116 - acc: 0.5933 - val_loss: 2.0035 - val_acc: 0.3710\n",
            "Epoch 6/500\n",
            "627/630 [============================>.] - ETA: 0s - loss: 1.2484 - acc: 0.6176Epoch 1/500\n",
            "630/630 [==============================] - 15s 24ms/step - loss: 1.2509 - acc: 0.6171 - val_loss: 2.0730 - val_acc: 0.3871\n",
            "Epoch 7/500\n",
            "629/630 [============================>.] - ETA: 0s - loss: 1.2799 - acc: 0.6244Epoch 1/500\n",
            "630/630 [==============================] - 16s 25ms/step - loss: 1.2827 - acc: 0.6242 - val_loss: 1.9271 - val_acc: 0.3763\n",
            "Epoch 8/500\n",
            "629/630 [============================>.] - ETA: 0s - loss: 1.1114 - acc: 0.6713Epoch 1/500\n",
            "630/630 [==============================] - 16s 25ms/step - loss: 1.1110 - acc: 0.6714 - val_loss: 1.7938 - val_acc: 0.4113\n",
            "Epoch 9/500\n",
            "629/630 [============================>.] - ETA: 0s - loss: 1.0613 - acc: 0.6872Epoch 1/500\n",
            "630/630 [==============================] - 15s 25ms/step - loss: 1.0645 - acc: 0.6869 - val_loss: 1.8619 - val_acc: 0.4086\n",
            "Epoch 10/500\n",
            "628/630 [============================>.] - ETA: 0s - loss: 1.0062 - acc: 0.7054Epoch 1/500\n",
            "630/630 [==============================] - 16s 25ms/step - loss: 1.0074 - acc: 0.7052 - val_loss: 1.6425 - val_acc: 0.4167\n",
            "Epoch 11/500\n",
            "629/630 [============================>.] - ETA: 0s - loss: 0.9696 - acc: 0.7051Epoch 1/500\n",
            "630/630 [==============================] - 15s 24ms/step - loss: 0.9702 - acc: 0.7052 - val_loss: 1.5677 - val_acc: 0.4355\n",
            "Epoch 12/500\n",
            "627/630 [============================>.] - ETA: 0s - loss: 0.8847 - acc: 0.7285Epoch 1/500\n",
            "630/630 [==============================] - 15s 24ms/step - loss: 0.8872 - acc: 0.7286 - val_loss: 1.6725 - val_acc: 0.3978\n",
            "Epoch 13/500\n",
            "627/630 [============================>.] - ETA: 0s - loss: 0.8455 - acc: 0.7440Epoch 1/500\n",
            "630/630 [==============================] - 15s 24ms/step - loss: 0.8498 - acc: 0.7429 - val_loss: 1.6219 - val_acc: 0.4005\n",
            "Epoch 14/500\n",
            "629/630 [============================>.] - ETA: 0s - loss: 0.8343 - acc: 0.7468Epoch 1/500\n",
            "630/630 [==============================] - 15s 25ms/step - loss: 0.8330 - acc: 0.7472 - val_loss: 1.5117 - val_acc: 0.4435\n",
            "Epoch 15/500\n",
            "626/630 [============================>.] - ETA: 0s - loss: 0.8385 - acc: 0.7420Epoch 1/500\n",
            "630/630 [==============================] - 16s 25ms/step - loss: 0.8361 - acc: 0.7421 - val_loss: 1.3951 - val_acc: 0.4382\n",
            "Epoch 16/500\n",
            " 40/630 [>.............................] - ETA: 13s - loss: 0.8489 - acc: 0.7563"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOTgQ2x9WiCN"
      },
      "source": [
        "# Examine EfficientNet Training Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i90iKXuL3CHT"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gRv7SwYqT9f"
      },
      "source": [
        "## Fine Tuning EfficientNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKI8AJxQVB1Q"
      },
      "source": [
        "# multiply_16\n",
        "# set 'multiply_16' and following layers trainable\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMjt8tCcDOoC"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch= NUM_TRAIN // batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps= NUM_TEST // batch_size,\n",
        "      verbose=1,\n",
        "      use_multiprocessing=True,\n",
        "      workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65AKWOGiHB5y"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_x = range(len(acc))\n",
        "\n",
        "plt.plot(epochs_x, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_x, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcYikQOyWsQf"
      },
      "source": [
        "# Save EfficientNet Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvVt5TwoEDz6"
      },
      "source": [
        "os.makedirs(\"./models\", exist_ok=True)\n",
        "model.save('./models/efficientNet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bigZr9kjL2sY"
      },
      "source": [
        "# Use EfficientNet Trained Model for Inference\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWTv_-7CHqZB"
      },
      "source": [
        "import random\n",
        "test_dir = '/content/efficientnet_keras_transfer_learning/test/'\n",
        "test_imgs = []\n",
        "for path, subdirs, files in os.walk(test_dir):\n",
        "    for name in files:\n",
        "        test_imgs.append(os.path.join(path, name))\n",
        "random_test_image = random.choice(test_imgs)\n",
        "random_test_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VFoNC0TLzaf"
      },
      "source": [
        "Image(filename=random_test_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLDHANW_HPVv"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "#recover class names from the train dataset generator\n",
        "class_lookup = dict((y,x) for x,y in train_generator.class_indices.items())\n",
        "\n",
        "def predict_image(img_path, class_lookup):\n",
        "    # Read the image and resize it\n",
        "    img = image.load_img(img_path, target_size=(height, width))\n",
        "    # Convert it to a Numpy array with target shape.\n",
        "    x = image.img_to_array(img)\n",
        "    # Reshape\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "    x /= 255.\n",
        "    result = model.predict([x])[0][0]\n",
        "    result_verbose = model.predict([x])\n",
        "    if result > 0.5:\n",
        "        animal = \"cat\"\n",
        "    else:\n",
        "        animal = \"dog\"\n",
        "        result = 1 - result\n",
        "    print(result_verbose)\n",
        "    predicted_class = class_lookup[np.argmax(result_verbose, axis=1)[0]]\n",
        "    predicted_probability = result_verbose[0][np.argmax(result_verbose, axis=1)[0]]\n",
        "\n",
        "    return predicted_class ,predicted_probability, result_verbose\n",
        "\n",
        "print(predict_image(random_test_image, class_lookup))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogB16XX3eXaN"
      },
      "source": [
        "## Download Trained EfficientNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_3Zek4eeSXD"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('./models/efficientNet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1rvrVx3CVN0"
      },
      "source": [
        "model.input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9O9mCbbVPWk"
      },
      "source": [
        "## Load Trained EfficientNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkBE5AZdwLki"
      },
      "source": [
        "from efficientnet.layers import Swish, DropConnect\n",
        "from efficientnet.model import ConvKernalInitializer\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'ConvKernalInitializer': ConvKernalInitializer,\n",
        "    'Swish': Swish,\n",
        "    'DropConnect':DropConnect\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pURT5B8uVFgq"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"./models/efficientNet.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}